<div id="ipython-notebook">
            <a class="interact-button" href="http://prob140.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/prob140/materials&branch=gh-pages&subPath=textbook/18_02_Sums_of_Independent_Normal_Variables.ipynb">Interact</a>
            
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sums-of-Independent-Normal-Variables">Sums of Independent Normal Variables<a class="anchor-link" href="#Sums-of-Independent-Normal-Variables">¶</a></h2></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This section consists of examples based on one important fact:</p>
<p><strong>The sum of independent normal variables is normal.</strong></p>
<p>We will prove the fact in a later section using moment generating functions. For now, we will just run a quick simulation and then see how to use the fact in examples.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mu_X</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">sigma_X</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">mu_Y</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">sigma_Y</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mu_X</span><span class="p">,</span> <span class="n">sigma_X</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mu_Y</span><span class="p">,</span> <span class="n">sigma_Y</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">x</span><span class="o">+</span><span class="n">y</span>
<span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_column</span><span class="p">(</span><span class="s1">'S = X+Y'</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'$X$ is normal (10, $2^2$); $Y$ is normal (15, $3^2$)'</span><span class="p">);</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="../notebooks-images/18_02_Sums_of_Independent_Normal_Variables_3_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The simulation above generates 10,000 copies of $X+Y$ where $X$ has the normal distribution with mean 10 and SD 2 and $Y$ is independent of $X$ and has the normal distribution with mean 15 and SD 3. The distribution of the sum is clearly normal. You can vary the parameters and check that the distribution of the sum has the same shape, though with different labels on the axes.</p>
<p>To identify which normal, you have to find the mean and variance of the sum. Just use properties of the mean and variance:</p>
<p>If $X$ has the normal $(\mu_X, \sigma_X^2)$ distribution, and $Y$ independent of $X$ has the normal $(\mu_Y, \sigma_Y^2)$ distribution, then the distribution of $X+Y$ is normal with mean $\mu_X + \mu_Y$ and variance $\sigma_X^2 + \sigma_Y^2$.</p>
<p>This means that we don't need the joint density of $X$ and $Y$ to find probabilities of events determined by $X+Y$.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sums-of-IID-Normal-Variables">Sums of IID Normal Variables<a class="anchor-link" href="#Sums-of-IID-Normal-Variables">¶</a></h3><p>Let $X_1, X_2, \ldots, X_n$ be i.i.d. normal with mean $\mu$ and variance $\sigma^2$. Let $S_n = X_1 + X_2 + \ldots + X_n$. Then the distribution of $S_n$ is normal with mean $n\mu$ and variance $n\sigma^2$.</p>
<p>This looks rather like the Central Limit Theorem but notice that there is no assumption that $n$ is large, and no approximation.</p>
<p>If the underlying distribution is normal, then the distribution of the i.i.d. sample sum is normal regardless of the sample size.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Difference-of-Two-Independent-Normal-Variables">The Difference of Two Independent Normal Variables<a class="anchor-link" href="#The-Difference-of-Two-Independent-Normal-Variables">¶</a></h3><p>If $Y$ is normal, then so is $-Y$. So if $X$ and $Y$ are independent normal variables then $X-Y$ is normal with mean $\mu_X - \mu_Y$ and variance given by
$$
Var(X - Y) ~ = ~
Var(X) + Var(-Y) ~ = ~
\sigma_X^2 + (-1)^2\sigma_Y^2 ~ = ~
\sigma_X^2 + \sigma_Y^2
$$</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For example, let the heights of Persons A and B be $H_A$ and $H_B$ respectively, and suppose $H_A$ and $H_B$ are i.i.d. normal with mean 66 inches and SD 3 inches. Then the chance that Person A is more than 2 inches taller than Person B is</p>
$$
P(H_A &gt; H_B + 2) = P(H_A - H_B &gt; 2) = 1 - \Phi\big{(}\frac{2 - 0}{\sqrt{18}}\big{)}
$$<p>because $H_A - H_B$ is normal with mean 0 and SD $\sqrt{3^2 + 3^2} = \sqrt{18} = 4.24$ inches.</p></div></div>
<div class="output_png output_subarea ">
<img src="../notebooks-images/18_02_Sums_of_Independent_Normal_Variables_8_0.png"/></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">18</span><span class="o">**</span><span class="mf">0.5</span>
<span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.31867594411696853</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Comparing-Two-Sample-Proportions">Comparing Two Sample Proportions<a class="anchor-link" href="#Comparing-Two-Sample-Proportions">¶</a></h3><p>A candidate is up for election. In State 1, 50% of the voters favor the candidate. In State 2, only 27% of the voters favor the candidate. A simple random sample of 1000 voters is taken in each state. You can assume that the samples are independent of each other and that there are millions of voters in each state.</p>
<p><strong>Question.</strong> Approximately what is the chance that in the sample from State 1, the proportion of voters who favor the candidate is more than twice as large as the proportion in the State 2 sample?</p>
<p><strong>Answer.</strong> For $i = 1, 2$, let $X_i$ be the proportion of voters who favor the candidate in the sample from State $i$. We want the approximate value of $P(X_1 &gt; 2X_2)$. By the Central Limit Theorem, both $X_1$ and $X_2$ are approximately normal. So $X_1 - 2X_2$ is also approximately normal.</p>
<p>Now it's just a matter of figuring out the mean and the SD.</p>
$$
E(X_1 - 2X_2) ~ = ~ 0.5 - 2\times 0.27 = -0.04
$$$$
Var(X_1) = \frac{0.5 \times 0.5}{1000} = 0.00025, ~~~~~~
Var(X_2) = \frac{0.27 \times 0.73}{1000} = 0.000197
$$$$
Var(X_1 - 2X_2) = Var(X_1) + 4Var(X_2) = 0.00104, ~~~~~~
SD(X_1 - 2X_2) = 0.03222
$$<p>So
$$
P(X_1 &gt; 2X_2) ~ = ~ P(X_1 - 2X_2 &gt; 0) 
~ \approx ~ 1 - \Phi \big{(} \frac{0 - (-0.04)}{0.03222} \big{)}
~ \approx ~ 10.7\%
$$</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="mf">0.27</span>
<span class="n">var</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">0.5</span><span class="o">/</span><span class="mi">1000</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="p">(</span><span class="mf">0.27</span><span class="o">*.</span><span class="mi">73</span><span class="o">/</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">var</span><span class="o">**</span><span class="mf">0.5</span>
<span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.1072469993885582</pre></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div></div></div></div>