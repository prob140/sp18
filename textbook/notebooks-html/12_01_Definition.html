<div id="ipython-notebook">
            <a class="interact-button" href="http://prob140.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/prob140/materials&branch=gh-pages&subPath=textbook/12_01_Definition.ipynb">Interact</a>
            
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Definition">Definition<a class="anchor-link" href="#Definition">¶</a></h2></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Measuring the rough size of the squared deviations has the advantage that it avoids cancellation between positive and negative errors. The disadvantage is that squared deviations have units that are difficult to understand. The measure of spread that we are about to define takes care of this problem.</p>
<h3 id="Root-Mean-Squared-Deviation-from-the-Mean">Root Mean Squared Deviation from the Mean<a class="anchor-link" href="#Root-Mean-Squared-Deviation-from-the-Mean">¶</a></h3><p>Let $X$ be a random variable with expectation $\mu_X$. The <em>standard deviation</em> of $X$, denoted $SD(X)$ or $\sigma_X$, is the root mean square of deviations from the mean:</p>
$$
SD(X) = \sigma_X = \sqrt{ E\big{(} (X-\mu_X)^2 \big{)} }
$$<p>$SD(X)$ has the same units as $X$ and $E(X)$. In this chapter we will make precise the sense in which the standard deviation measures the spread of the distribution of $X$ about the center $\mu_X$.</p>
<p>The quantity inside the square root is called the <em>variance</em> of $X$ and has better computational properties than the SD. This turns out to be closely connected to the fact that by Pythagoras' Theorem, squares of distances combine in useful ways.</p>
$$
Var(X) = \sigma_X^2 = E\big{(} (X-\mu_X)^2 \big{)}
$$<p>Almost invariably, we will calculate standard deviations by first finding the variance and then taking the square root.</p>
<p>Let's try out the definition of the SD on a random variable $X$ that has the distribution defined below.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">make_array</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">make_array</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">dist_X</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">probability</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="n">dist_X</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Value</th> <th>Probability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>3    </td> <td>0.2        </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>4    </td> <td>0.5        </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>5    </td> <td>0.3        </td>
        </tr>
    </tbody>
</table></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dist_X</span><span class="o">.</span><span class="n">ev</span><span class="p">()</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>4.0999999999999996</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are the squared deviations from the expectation $E(X) = 4.1$.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sd_table</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
    <span class="s1">'x'</span><span class="p">,</span> <span class="n">dist_X</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">'(x - 4.1)**2'</span><span class="p">,</span> <span class="p">(</span><span class="n">dist_X</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="mf">4.1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>
    <span class="s1">'P(X = x)'</span><span class="p">,</span> <span class="n">dist_X</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">sd_table</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>x</th> <th>(x - 4.1)**2</th> <th>P(X = x)</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>3   </td> <td>1.21        </td> <td>0.2     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>4   </td> <td>0.01        </td> <td>0.5     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>5   </td> <td>0.81        </td> <td>0.3     </td>
        </tr>
    </tbody>
</table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The standard deviation of $X$ is the square root of the mean squared deviation. The calculation below shows that its numerical value is $SD(X) = 0.7$.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sd_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">sd_table</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">sd_table</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">sd_X</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.69999999999999996</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>prob140</code> method <code>sd</code> applied to a distribution object returns the standard deviation, saving you the calculation above.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dist_X</span><span class="o">.</span><span class="n">sd</span><span class="p">()</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.7</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now know how to calculate the SD. But we don't yet have a good understanding of what it does. Let's start developing a few properties that it ought to have. Then we can check if it has them.</p>
<p>First, the SD of a constant should be 0. You should check that this is indeed what the definition implies.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Shifting-and-Scaling">Shifting and Scaling<a class="anchor-link" href="#Shifting-and-Scaling">¶</a></h3><p>The SD is a measure of spread. It's natural to want measures of spread to remain unchanged if we just shift a probability histogram to the left or right. Such a shift occurs when we add a constant to a random variable. The figure below shows the distribution of the same $X$ as above, along with the distribution of $X+5$. It is clear that $X+5$ should have the same SD as $X$.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dist2</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">probability</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="n">Plots</span><span class="p">(</span><span class="s1">'X'</span><span class="p">,</span> <span class="n">dist_X</span><span class="p">,</span> <span class="s1">'X+5'</span><span class="p">,</span> <span class="n">dist2</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="../notebooks-images/12_01_Definition_13_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On the other hand, multiplying $X$ by a constant results in a distribution that should have a different spread. Here is the distribution of $X$ along with the distribution of $4X$. The spread of the distribution of $4X$ appears to be four times as large as that of $X$.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dist3</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">probability</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="n">Plots</span><span class="p">(</span><span class="s1">'X'</span><span class="p">,</span> <span class="n">dist_X</span><span class="p">,</span> <span class="s1">'4X'</span><span class="p">,</span> <span class="n">dist3</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">40</span><span class="p">);</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="../notebooks-images/12_01_Definition_15_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Multiplying by $-4$ should have the same effect on the spread as multiplying by 4, as the figure below shows. One histogram is just the mirror image of the other about the vertical axis at 0. There is no change in spread.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dist4</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">probability</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="n">Plots</span><span class="p">(</span><span class="s1">'-4X'</span><span class="p">,</span> <span class="n">dist4</span><span class="p">,</span> <span class="s1">'4X'</span><span class="p">,</span> <span class="n">dist3</span> <span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="../notebooks-images/12_01_Definition_17_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The graphs above help us visualize what happens to the SD when the random variable is transformed linearly. Let $Y = aX + b$. Then</p>
\begin{align*}
Var(Y) = E\big{[} (Y-\mu_Y)^2 \big{]} &amp;= E\big{[} (aX + b - a\mu_X - b)^2 \big{]}\\ 
&amp;= a^2 E \big{[} (X - \mu_X)^2 \big{]}\\ 
&amp;= a^2 \sigma_X^2
\end{align*}<p>Notice that the shift $b$ has no effect on the variance. This is consistent with what we saw in the first visualization above.</p>
<p>Because the units of the variance are the square of the units of $X$, $Var(Y)$ is $a^2$ times the variance of $X$. Thus $SD(Y)$ is</p>
$$
SD(aX + b) = |a|\sigma_X
$$<p>Notice that you get the same answer when the multiplicative constant is $a$ as when it is $-a$. That is what the two "mirror image" histograms had shown.</p>
<p>In particular, it is very handy to remember that $SD(X) = SD(-X)$.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id='"Computational"-Formula-for-Variance'>"Computational" Formula for Variance<a class="anchor-link" href='#"Computational"-Formula-for-Variance'>¶</a></h3><p>An algebraic simplification of the formula for variance turns out to be very useful.</p>
\begin{align*}
\sigma_X^2 &amp;= E\big{(} (X-\mu_X)^2 \big{)} \\ \\
&amp;= E(X^2 - 2X\mu_X + \mu_X^2) \\ \\
&amp;= E(X^2) - 2\mu_XE(X) + \mu_X^2 \\ \\
&amp;= E(X^2) - 2\mu_X^2 + \mu_X^2 \\ \\
&amp;= E(X^2) - \mu_X^2 
\end{align*}<p>Thus the variance is the "mean of the square minus the square of the mean."</p>
<p>Though this is often called the "computational" formula for variance, it can be be numerically inaccurate if the possible values of $X$ are large and numerous. For algebraic computation, however, it is very useful. Here are several examples.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Indicator">Indicator<a class="anchor-link" href="#Indicator">¶</a></h3><p>The values of an indicator random variable are 0 and 1. Each of those two numbers is equal to its square. So if $I$ is an indicator, then $I^2 = I$, and thus</p>
$$
Var(I) = E(I^2) - [E(I)]^2 = E(I) - [E(I)]^2 = p - p^2 = p(1-p)
$$<p>You should check that this variance is largest when $p = 0.5$. Take the square root to get</p>
$$
SD(I) = \sqrt{p(1-p)}
$$</div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Uniform">Uniform<a class="anchor-link" href="#Uniform">¶</a></h3><p>Let $U$ be uniform on $1, 2, 3, \ldots, n$. Then</p>
\begin{align*}
E(U^2) &amp;= \sum_{k=1}^n k^2 \cdot \frac{1}{n} \\ \\
&amp;= \frac{1}{n} \sum_{k=1}^n k^2 \\ \\
&amp;= \frac{1}{n} \cdot \frac{n(n+1)(2n+1)}{6} \\ \\
&amp;= \frac{(n+1)(2n+1)}{6}
\end{align*}<p>In the last-but-one step above, we used the formula for the sum of the first $n$ squares.</p>
<p>We know that $E(U) = (n+1)/2$, so</p>
$$
Var(U) = \frac{(n+1)(2n+1)}{6} - \frac{(n+1)^2}{4}
= \frac{n+1}{2} \big{(} \frac{2n+1}{3} - \frac{n+1}{2} \big{)}
= \frac{n^2-1}{12}
$$<p>and</p>
$$
SD(U) = \sqrt{\frac{n^2-1}{12}}
$$<p>By shifting, this is the same as the SD of the uniform distribution on any $n$ consecutive integers.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Poisson">Poisson<a class="anchor-link" href="#Poisson">¶</a></h3><p>Let $X$ have the Poisson $(\mu)$ distribution. In the previous chapter we showed that</p>
$$
E(X^2) = \mu^2 + \mu
$$<p>We also know that $E(X) = \mu$. Thus
$$
Var(X) = \mu^2 + \mu - \mu^2 = \mu
$$</p>
<p>and 
$$
SD(X) = \sqrt{\mu}
$$</p>
<p>So for example if $X$ has the Poisson $(5)$ distribution, then $E(X) = 5$ and $SD(X) = \sqrt{5} \approx 2.24$. In the remainder of this chapter, we will try to figure out what that means.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div></div></div></div>