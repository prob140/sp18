<div id="ipython-notebook">
            <a class="interact-button" href="http://prob140.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/prob140/materials&branch=gh-pages&subPath=textbook/9_02_Expectation_by_Conditioning.ipynb">Interact</a>
            
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Expectation-by-Conditioning">Expectation by Conditioning<a class="anchor-link" href="#Expectation-by-Conditioning">Â¶</a></h2></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let $T$ be a random variable, and let $S$ be a random variable defined on the same space as $T$. As we have seen, conditioning on $S$ might be a good way to find probabilities for $T$ if $S$ and $T$ are related. In this section we will see that conditioning on $S$ can also be a good way to find the expectation of $T$.</p>
<p>We will start with a simple example to illustrate the ideas. Let the joint distribution of $T$ and $S$ be as in the table below.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">pp</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
<span class="n">jd2</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="s1">'T'</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s1">'S'</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">probability</span><span class="p">(</span><span class="n">pp</span><span class="p">)</span>
<span class="n">jt_dist</span> <span class="o">=</span> <span class="n">jd2</span><span class="o">.</span><span class="n">to_joint</span><span class="p">()</span>
<span class="n">jt_dist</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T=3</th>
      <th>T=4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>S=7</th>
      <td>0.3</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>S=6</th>
      <td>0.2</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>S=5</th>
      <td>0.1</td>
      <td>0.1</td>
    </tr>
  </tbody>
</table></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How can $S$ be involved in the calculation of $E(T)$?</p>
<p>Notice that to find $E(T)$, you could use the joint distribution table and the definition of expectation as follows:</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span> 
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>3.4</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is equivalent to going to each cell of the table, weighting the value of $T$ in that cell with the probability in the cell, and then adding. Here's another way of looking at this.</p>
<p>Let's condition on $S$:</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">jt_dist</span><span class="o">.</span><span class="n">conditional_dist</span><span class="p">(</span><span class="s1">'T'</span><span class="p">,</span> <span class="s1">'S'</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T=3</th>
      <th>T=4</th>
      <th>Sum</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Dist. of T | S=7</th>
      <td>0.75</td>
      <td>0.25</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Dist. of T | S=6</th>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Dist. of T | S=5</th>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Marginal of T</th>
      <td>0.60</td>
      <td>0.40</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each of the three conditional distributions is a distribution in its own right. Therefore its histogram has a balance point, just as the marginal distribution of $T$ does.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">jt_dist</span><span class="o">.</span><span class="n">conditional_dist</span><span class="p">(</span><span class="s1">'T'</span><span class="p">,</span> <span class="s1">'S'</span><span class="p">,</span> <span class="n">show_ev</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T=3</th>
      <th>T=4</th>
      <th>Sum</th>
      <th>EV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Dist. of T | S=7</th>
      <td>0.75</td>
      <td>0.25</td>
      <td>1.0</td>
      <td>3.25</td>
    </tr>
    <tr>
      <th>Dist. of T | S=6</th>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.0</td>
      <td>3.50</td>
    </tr>
    <tr>
      <th>Dist. of T | S=5</th>
      <td>0.50</td>
      <td>0.50</td>
      <td>1.0</td>
      <td>3.50</td>
    </tr>
    <tr>
      <th>Marginal of T</th>
      <td>0.60</td>
      <td>0.40</td>
      <td>1.0</td>
      <td>3.40</td>
    </tr>
  </tbody>
</table></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see $E(T) = 3.4$ in the row corresponding to the distribution of $T$. And you can also see the <em>conditional expectation of $T$</em> given each possible value of $S$:</p>
<ul>
<li>$~E(T \mid S=5) = 3.5$</li>
<li>$~E(T \mid S=6) = 3.5$</li>
<li>$~E(T \mid S=7) = 3.25$</li>
</ul>
<p>This defines a <em>function of $S$</em>: for each value $s$ of $S$, the function returns $E(T \mid S=s)$.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ev_T_given_S</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
    <span class="s1">'s'</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span>
    <span class="s1">'E(T | S = s)'</span><span class="p">,</span> <span class="p">[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">3.25</span><span class="p">],</span>
    <span class="s1">'P(S = s)'</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">ev_T_given_S</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>s</th> <th>E(T | S = s)</th> <th>P(S = s)</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>5   </td> <td>3.5         </td> <td>0.2     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>6   </td> <td>3.5         </td> <td>0.4     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>7   </td> <td>3.25        </td> <td>0.4     </td>
        </tr>
    </tbody>
</table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function of $S$ is called the <em>conditional expectation of $T$ given $S$</em> and is denoted $E(T \mid S)$. Unlike expectation which is a number, conditional expectation is a random variable.</p>
<p>As it's a random variable, it has an expectation, which we can calculate using the non-linear function rule. The answer is a quantity that you will recognize.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ev</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ev_T_given_S</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">'E(T | S = s)'</span><span class="p">)</span><span class="o">*</span><span class="n">ev_T_given_S</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">'P(S = s)'</span><span class="p">))</span>
<span class="n">ev</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>3.4000000000000004</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's right: it's the expectation of $T$.</p>
<p>What we have learned from this is that $E(T)$ is the <em>average of the conditional expectations of $T$ given the different values of $S$, weighted by the probabilities of those values</em>.</p>
<p>In short, $E(T)$ is the <em>expectation of the conditional expectation of $T$ given $S$</em>.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conditional-Expectation-as-a-Random-Variable">Conditional Expectation as a Random Variable<a class="anchor-link" href="#Conditional-Expectation-as-a-Random-Variable">Â¶</a></h3><p>In general, suppose $T$ and $S$ are two random variables on a probability space.</p>
<p>Then for each fixed value of $s$, $T$ has a conditional distribution given $S=s$. This is an ordinary distribution and has an expectation. That is called the <em>expectation of $T$ given $S=s$</em> and is denoted $E(T \mid S = s)$.</p>
<p>So for each $s$, there is a value $E(T \mid S=s)$. This defines a function of the random variable $S$. It is called the <em>conditional expectation of $T$ given $S$</em>, and is denoted $E(T \mid S)$.</p>
<p>The key difference between expectation and conditional expectation:</p>
<ul>
<li>$E(T)$, the expectation of $T$, is a real number.</li>
<li>$E(T \mid S)$, the conditional expectation of $T$ given $S$, is a function of $S$ and hence is a random variable.</li>
</ul>
<p>Since $E(T \mid S)$ is a random variable, it has an expectation. That expectation is equal to $E(T)$. We observed this in an example; now here is a proof.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Iterated-Expectations">Iterated Expectations<a class="anchor-link" href="#Iterated-Expectations">Â¶</a></h3><p>Suppose we want the expectation of a random variable, and suppose it is easy for us to say what that expectation would be if we were given the value of a related random variable. The rule of <em>iterated expectations</em> says that we can find that conditional expectation first, and take its expectation to get our answer.</p>
<p>Formally, let $S$ and $T$ be two random variables on the same space. Then $E(T) = E(E(T \mid S))$.</p>
<p>Proof:</p>
\begin{align*}
E(T) &amp;= \sum_{\text{all }t} tP(T=t) \\ \\
&amp;= \sum_{\text{all }t} t \sum_{\text{all }s} P(S=s, T=t) \\ \\
&amp;= \sum_{\text{all }t} t \sum_{\text{all }s} P(S=s)P(T=t \mid S=s) \\ \\
&amp;= \sum_{\text{all }s} \Big{(} \sum_{\text{all }t} tP(T=t \mid S=s) \Big{)} P(S=s) \\ \\
&amp;= \sum_{\text{all }s} E(T \mid S=s)P(S=s) \\ \\
&amp;= E(E(T \mid S))
\end{align*}</div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Random-Sums">Random Sums<a class="anchor-link" href="#Random-Sums">Â¶</a></h3><p>Let $X_1, X_2, \ldots $ be i.i.d. and let $E(X_1) = \mu_X$. Let $N$ be a non-negative integer valued random variable that is independent of the sequence of $X$'s and let $E(N) = \mu_N$.</p>
<p>Define the <em>random sum</em> $S$ to be</p>
$$
S = X_1 + X_2 + \ldots + X_N
$$<p>where $S = 0$ if $N=0$.</p>
<p>Notice that $S$ is the sum of a random number of terms.</p>
<p><strong>Question.</strong> What is $E(S)$?</p>
<p><strong>Answer.</strong> If $N$ were the constant 10, then the answer would be $10\mu_X$. This is our signal to condition on $N$. Here are the steps to follow.</p>
<ul>
<li>First condition on a fixed value of $N$. Given $N=n$, $S$ is the sum of $n$ i.i.d. terms. Hence 
$$
E(S \mid N=n) = n\mu_X
$$ 
This is an equality of real numbers. Note that it is true for all $n$, including 0.</li>
<li>Next write the conditional expectation in random variable notation.
$$
E(S \mid N) = N\mu_X
$$
This is an equality of random variables.</li>
<li>Now use iterated expectations.
$$
E(S) = E(E(S \mid N)) = E(N\mu_X) = E(N)\mu_X = \mu_N\mu_X
$$</li>
</ul>
<p>This is a natural answer. It is the expected number of terms being added times the expected size of each of those terms.</p>
<p>This is an important point to note about calculating expectations by conditioning. The natural answer is often correct.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Population-Size-in-a-Branching-Process">Population Size in a Branching Process<a class="anchor-link" href="#Population-Size-in-a-Branching-Process">Â¶</a></h3><p>In a <em>Galton-Watson branching process</em>, each individual has a random number of progeny. Assume that the numbers of progeny of the different indviduals are i.i.d. with mean $\mu$. Suppose the process starts with one individual in Generation 0.</p>
<p><strong>Question.</strong> Assuming that there are no deaths, what is the expected total number of individuals in Generations 0 through $n$?</p>
<p><strong>Answer.</strong> Let $T_k$ be the number of individuals born in Generation $k$. We are assuming $T_0 = 1$. By the example above, for each $k &gt; 1$,</p>
$$
E(T_k) = E(T_{k-1})\mu
$$<p>So by induction, for each $k &gt; 1$ the expected number of people in Generation $k$ is</p>
$$
E(T_k) = \mu^k
$$<p>Indeed, the result is true for $k=0$ as well. So the expected total number of people through Generation $n$ is</p>
\begin{equation}
\sum_{k=0}^n \mu^k = 
 \begin{cases} 
      n &amp; \text{if } \mu = 1 \\
      \frac{1 - \mu^{n+1}}{1 - \mu} = \frac{\mu^{n+1} - 1}{\mu - 1} &amp; \text{if } \mu \ne 1
   \end{cases}
\end{equation}<p>The value of $\mu$, the expected number of progeny of a single individual, determines how this expected total behaves as $n$ gets large. Even with no deaths, if $\mu &lt; 1$ the expected population size tends to a positive constant as $n \to \infty$. But if $\mu \ge 1$ then the expected population size explodes.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Other-Properties-of-Conditional-Expectation">Other Properties of Conditional Expectation<a class="anchor-link" href="#Other-Properties-of-Conditional-Expectation">Â¶</a></h3><p>The most important property of conditional expectation is the iteration that we have studied in this section. But conditional expectation has other properties that are analogous to those of expectation. <strong>They are now expressed as equalities of random variables instead of equalities of real numbers.</strong></p>
<p>Go through the list and notice that all the moves you'd naturally want to make are justified. The proofs are routine; we won't go through them.</p>
<ul>
<li><strong>Additivity.</strong> $~E(T+U \mid S) = E(T \mid S) + E(U \mid S)$</li>
<li><strong>Linear Transformation.</strong> $~E(aT+b \mid S) = aE(T \mid S) + b$</li>
</ul>
<p>Two more properties formalize the idea that the variable that is given can be treated as a constant in conditional expectations.</p>
<ul>
<li><strong>"Constant"</strong>: Let $g$ be a function. Then $E(g(S) \mid S) = g(S)$.</li>
<li><strong>"Pulling out a Constant"</strong>: $~E(g(S)T \mid S) = g(S)E(T \mid S)$.</li>
</ul>
<p>For example,
$$
E(3ST + \log(S)U + 7 \mid S) = 3SE(T \mid S) + \log(S)E(U \mid S) + 7
$$</p>
<p>though we sincerely hope you won't encounter a random variable as bizarre as this.</p></div></div></div>